{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# load model\n",
    "from latent_ode.trainer_glunet_interpol import LatentODEWrapper\n",
    "from latent_ode.eval_glunet import test\n",
    "\n",
    "# utils for darts\n",
    "from utils.darts_training import print_callback\n",
    "from utils.darts_dataset import SamplingDatasetDual, SamplingDatasetInferenceDual\n",
    "from utils.darts_processing import load_data, reshuffle_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Loading column definition...\n",
      "Checking column definition...\n",
      "Loading data...\n",
      "Dropping columns / rows...\n",
      "Checking for NA values...\n",
      "Setting data types...\n",
      "Dropping columns / rows...\n",
      "Encoding data...\n",
      "\tUpdated column definition:\n",
      "\t\tid: REAL_VALUED (ID)\n",
      "\t\ttime: DATE (TIME)\n",
      "\t\tgl: REAL_VALUED (TARGET)\n",
      "\t\tAge: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tBMI: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tA1C: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tFBG: REAL_VALUED (STATIC_INPUT)\n",
      "\t\togtt.2hr: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tinsulin: REAL_VALUED (STATIC_INPUT)\n",
      "\t\ths.CRP: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tTchol: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tTrg: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tHDL: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tLDL: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmean_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tsd_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\trange_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmin_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmax_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tquartile.25_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmedian_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tquartile.75_glucose: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmean_slope: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmax_slope: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random140: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random200: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tpercent_below.80: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tse_glucose_mean: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumGE: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmage: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tj_index: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tIQR: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tmodd: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdistance_traveled: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tcoef_variation: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random140_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumber_Random200_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tnumGE_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdistance_traveled_normByDays: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tdiagnosis: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_low: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_moderate: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tfreq_severe: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tglucotype: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tHeight: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tWeight: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tInsulin_rate_dd: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tperc_cgm_prediabetic_range: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tperc_cgm_diabetic_range: REAL_VALUED (STATIC_INPUT)\n",
      "\t\tSSPG: REAL_VALUED (STATIC_INPUT)\n",
      "\t\ttime_year: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_month: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_day: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_hour: REAL_VALUED (KNOWN_INPUT)\n",
      "\t\ttime_minute: REAL_VALUED (KNOWN_INPUT)\n",
      "Interpolating data...\n",
      "\tDropped segments: 160\n",
      "\tExtracted segments: 152\n",
      "\tInterpolated values: 8003\n",
      "\tPercent of values interpolated: 8.57%\n",
      "Splitting data...\n",
      "\tTrain: 62461 (61.57%)\n",
      "\tVal: 12357 (12.18%)\n",
      "\tTest: 16517 (16.28%)\n",
      "\tTest OOD: 10113 (9.97%)\n",
      "Scaling data...\n",
      "\tNo scaling applied\n",
      "Data formatting complete.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "formatter, series, scalers = load_data(seed=0, \n",
    "                                       study_file=None, \n",
    "                                       dataset='hall',\n",
    "                                       use_covs=True, \n",
    "                                       cov_type='dual',\n",
    "                                       use_static_covs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, j in enumerate(random.sample(range(len(series['train']['target'])), 3)):\n",
    "    s = scalers['target'].inverse_transform(series['train']['target'][j])\n",
    "    id = scalers['static'].inverse_transform(series['train']['static'][j])\n",
    "    id = id.values()[0, -1]\n",
    "    s.plot(ax=axs[i])\n",
    "    axs[i].set_title(f'Patient {int(id)}')\n",
    "    axs[i].set_ylabel('Glucose (mg/dL)')\n",
    "    axs[i].set_xlabel('Time (date)')\n",
    "    if axs[i].get_legend() is not None:\n",
    "        axs[i].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "out_len = 12\n",
    "in_len = 24\n",
    "max_samples_per_ts = 100\n",
    "dataset_train = SamplingDatasetDual(series['train']['target'],\n",
    "                                    series['train']['future'],\n",
    "                                    output_chunk_length=out_len,\n",
    "                                    input_chunk_length=in_len,\n",
    "                                    use_static_covariates=True,\n",
    "                                    max_samples_per_ts=max_samples_per_ts,)\n",
    "dataset_val = SamplingDatasetDual(series['val']['target'],\n",
    "                                    series['val']['future'],   \n",
    "                                    output_chunk_length=out_len,\n",
    "                                    input_chunk_length=in_len,\n",
    "                                    use_static_covariates=True,)\n",
    "dataset_test = SamplingDatasetInferenceDual(target_series=series['test']['target'],\n",
    "                                            covariates=series['test']['future'],\n",
    "                                            input_chunk_length=in_len,\n",
    "                                            output_chunk_length=out_len,\n",
    "                                            use_static_covariates=True,\n",
    "                                            array_output_only=True)\n",
    "dataset_test_ood = SamplingDatasetInferenceDual(target_series=series['test_ood']['target'],\n",
    "                                                covariates=series['test_ood']['future'],\n",
    "                                                input_chunk_length=in_len,\n",
    "                                                output_chunk_length=out_len,\n",
    "                                                use_static_covariates=True,\n",
    "                                                array_output_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert samples to series\n",
    "import darts\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_len = 1\n",
    "in_len =  48\n",
    "max_samples_per_ts = 100\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentODEWrapper(device = 'cuda',\n",
    "                         latents = 5,\n",
    "                         rec_dims = 50,\n",
    "                         rec_layers = 3,\n",
    "                         gen_layers = 3,\n",
    "                         units = 300,\n",
    "                         gru_units = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/m/mrsergazinov/.conda/envs/glunet/lib/python3.10/site-packages/torchdiffeq/_impl/misc.py:296: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
      "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n",
      "/home/grads/m/mrsergazinov/latent_ode_example/latent_ode/plotting.py:106: RuntimeWarning: invalid value encountered in divide\n",
      "  dydt = (dydt / mag)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moutput/model.ckpt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m'\u001b[39m\u001b[39moutput/tensorboard\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m           dataset_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m           learning_rate \u001b[39m=\u001b[39;49m \u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m           batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m           epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m           num_samples \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m           device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m           model_path \u001b[39m=\u001b[39;49m model_path,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m           trial \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m           logger \u001b[39m=\u001b[39;49m writer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Becewkgsw223b01.engr.tamu.edu/home/grads/m/mrsergazinov/latent_ode_example/example.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m           visualize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,)\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/trainer_glunet_interpol.py:220\u001b[0m, in \u001b[0;36mLatentODEWrapper.fit\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, batch_size, epochs, num_samples, device, model_path, trial, logger, visualize)\u001b[0m\n\u001b[1;32m    209\u001b[0m     batch_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m    210\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m'\u001b[39m: batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device),\n\u001b[1;32m    211\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobserved_tp\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, inp_len)\u001b[39m.\u001b[39mto(device) \u001b[39m/\u001b[39m \u001b[39m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39minterp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    218\u001b[0m     }\n\u001b[1;32m    219\u001b[0m     \u001b[39m# compute loss\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     train_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcompute_all_losses(batch_dict, n_traj_samples\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, kl_coef\u001b[39m=\u001b[39;49mkl_coef)\n\u001b[1;32m    221\u001b[0m     loss \u001b[39m=\u001b[39m train_res[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/base_models.py:256\u001b[0m, in \u001b[0;36mVAE_Baseline.compute_all_losses\u001b[0;34m(self, batch_dict, n_traj_samples, kl_coef)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_all_losses\u001b[39m(\u001b[39mself\u001b[39m, batch_dict, n_traj_samples \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, kl_coef \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m):\n\u001b[1;32m    254\u001b[0m \t\u001b[39m# Condition on subsampled points\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \t\u001b[39m# Make predictions for all the points\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m \tpred_y, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_reconstruction(batch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mtp_to_predict\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[1;32m    257\u001b[0m \t\tbatch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mobserved_data\u001b[39;49m\u001b[39m\"\u001b[39;49m], batch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mobserved_tp\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[1;32m    258\u001b[0m \t\tmask \u001b[39m=\u001b[39;49m batch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mobserved_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m], n_traj_samples \u001b[39m=\u001b[39;49m n_traj_samples,\n\u001b[1;32m    259\u001b[0m \t\tmode \u001b[39m=\u001b[39;49m batch_dict[\u001b[39m\"\u001b[39;49m\u001b[39mmode\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    261\u001b[0m \t\u001b[39m#print(\"get_reconstruction done -- computing likelihood\")\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \tfp_mu, fp_std, fp_enc \u001b[39m=\u001b[39m info[\u001b[39m\"\u001b[39m\u001b[39mfirst_point\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/latent_ode.py:60\u001b[0m, in \u001b[0;36mLatentODE.get_reconstruction\u001b[0;34m(self, time_steps_to_predict, truth, truth_time_steps, mask, n_traj_samples, run_backwards, mode)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m \ttruth_w_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((truth, mask), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m first_point_mu, first_point_std \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_z0(\n\u001b[1;32m     61\u001b[0m \ttruth_w_mask, truth_time_steps, run_backwards \u001b[39m=\u001b[39;49m run_backwards)\n\u001b[1;32m     63\u001b[0m means_z0 \u001b[39m=\u001b[39m first_point_mu\u001b[39m.\u001b[39mrepeat(n_traj_samples, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m sigma_z0 \u001b[39m=\u001b[39m first_point_std\u001b[39m.\u001b[39mrepeat(n_traj_samples, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/glunet/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/encoder_decoder.py:223\u001b[0m, in \u001b[0;36mEncoder_z0_ODE_RNN.forward\u001b[0;34m(self, data, time_steps, run_backwards, save_info)\u001b[0m\n\u001b[1;32m    220\u001b[0m \textra_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m \tlast_yi, last_yi_std, _, extra_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_odernn(\n\u001b[1;32m    224\u001b[0m \t\tdata, time_steps, run_backwards \u001b[39m=\u001b[39;49m run_backwards,\n\u001b[1;32m    225\u001b[0m \t\tsave_info \u001b[39m=\u001b[39;49m save_info)\n\u001b[1;32m    227\u001b[0m means_z0 \u001b[39m=\u001b[39m last_yi\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, n_traj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_dim)\n\u001b[1;32m    228\u001b[0m std_z0 \u001b[39m=\u001b[39m last_yi_std\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, n_traj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_dim)\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/encoder_decoder.py:285\u001b[0m, in \u001b[0;36mEncoder_z0_ODE_RNN.run_odernn\u001b[0;34m(self, data, time_steps, run_backwards, save_info)\u001b[0m\n\u001b[1;32m    282\u001b[0m \tn_intermediate_tp \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m2\u001b[39m, ((prev_t \u001b[39m-\u001b[39m t_i) \u001b[39m/\u001b[39m minimum_step)\u001b[39m.\u001b[39mint())\n\u001b[1;32m    284\u001b[0m \ttime_points \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mlinspace_vector(prev_t, t_i, n_intermediate_tp)\n\u001b[0;32m--> 285\u001b[0m \tode_sol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mz0_diffeq_solver(prev_y, time_points)\n\u001b[1;32m    287\u001b[0m \t\u001b[39massert\u001b[39;00m(\u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39misnan(ode_sol)\u001b[39m.\u001b[39many())\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mmean(ode_sol[:, :, \u001b[39m0\u001b[39m, :]  \u001b[39m-\u001b[39m prev_y) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/glunet/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/latent_ode_example/latent_ode/diffeq_solver.py:40\u001b[0m, in \u001b[0;36mDiffeqSolver.forward\u001b[0;34m(self, first_point, time_steps_to_predict, backwards)\u001b[0m\n\u001b[1;32m     37\u001b[0m n_traj_samples, n_traj \u001b[39m=\u001b[39m first_point\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m], first_point\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m n_dims \u001b[39m=\u001b[39m first_point\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m pred_y \u001b[39m=\u001b[39m odeint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mode_func, first_point, time_steps_to_predict, \n\u001b[1;32m     41\u001b[0m \trtol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49modeint_rtol, atol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49modeint_atol, method \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mode_method)\n\u001b[1;32m     42\u001b[0m pred_y \u001b[39m=\u001b[39m pred_y\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39massert\u001b[39;00m(torch\u001b[39m.\u001b[39mmean(pred_y[:, :, \u001b[39m0\u001b[39m, :]  \u001b[39m-\u001b[39m first_point) \u001b[39m<\u001b[39m \u001b[39m0.001\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/glunet/lib/python3.10/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[39m=\u001b[39m SOLVERS[method](func\u001b[39m=\u001b[39mfunc, y0\u001b[39m=\u001b[39my0, rtol\u001b[39m=\u001b[39mrtol, atol\u001b[39m=\u001b[39matol, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m event_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49mintegrate(t)\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39mintegrate_until_event(t[\u001b[39m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/.conda/envs/glunet/lib/python3.10/site-packages/torchdiffeq/_impl/solvers.py:110\u001b[0m, in \u001b[0;36mFixedGridODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mwhile\u001b[39;00m j \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(t) \u001b[39mand\u001b[39;00m t1 \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m t[j]:\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterp \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 110\u001b[0m         solution[j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_linear_interp(t0, t1, y0, y1, t[j])\n\u001b[1;32m    111\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterp \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcubic\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m         f1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(t1, y1)\n",
      "File \u001b[0;32m~/.conda/envs/glunet/lib/python3.10/site-packages/torchdiffeq/_impl/solvers.py:166\u001b[0m, in \u001b[0;36mFixedGridODESolver._linear_interp\u001b[0;34m(self, t0, t1, y0, y1, t)\u001b[0m\n\u001b[1;32m    163\u001b[0m     dt \u001b[39m=\u001b[39m (t1 \u001b[39m-\u001b[39m t0)\n\u001b[1;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m h00 \u001b[39m*\u001b[39m y0 \u001b[39m+\u001b[39m h10 \u001b[39m*\u001b[39m dt \u001b[39m*\u001b[39m f0 \u001b[39m+\u001b[39m h01 \u001b[39m*\u001b[39m y1 \u001b[39m+\u001b[39m h11 \u001b[39m*\u001b[39m dt \u001b[39m*\u001b[39m f1\n\u001b[0;32m--> 166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_linear_interp\u001b[39m(\u001b[39mself\u001b[39m, t0, t1, y0, y1, t):\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m t0:\n\u001b[1;32m    168\u001b[0m         \u001b[39mreturn\u001b[39;00m y0\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = 'output/model.ckpt'\n",
    "writer = SummaryWriter('output/tensorboard')\n",
    "model.fit(dataset_train,\n",
    "          dataset_train,\n",
    "          learning_rate = 1e-3,\n",
    "          batch_size = 32,\n",
    "          epochs = 100,\n",
    "          num_samples = 2,\n",
    "          device = 'cuda',\n",
    "          model_path = model_path,\n",
    "          trial = None,\n",
    "          logger = writer,\n",
    "          visualize=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230426-164445'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109294/2803185994.py:21: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f'./plots/{folder}/{file}'))\n"
     ]
    }
   ],
   "source": [
    "# list folders in the directory plots\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "folders = os.listdir('./plots')\n",
    "# in each folder, grab list of files\n",
    "\n",
    "m = {'20230426-165058': 'glucose_id',\n",
    "     '20230426-165144': 'periodic_id',\n",
    "     '20230426-204814': 'periodic_interpol',\n",
    "     '20230426-204841': 'glucose_interpol',\n",
    "     '20230426-204954': 'glucose_extrapol',}\n",
    "for folder in folders:\n",
    "    files = os.listdir(f'./plots/{folder}')\n",
    "    files = sorted(files, key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    select1 = np.linspace(0, 200, 60, dtype=int)\n",
    "    select2 = np.linspace(200, len(files)-1, 60, dtype=int)\n",
    "    files = [files[i] for i in select1] + [files[i] for i in select2]\n",
    "    images = []\n",
    "    for file in files:\n",
    "        images.append(imageio.imread(f'./plots/{folder}/{file}'))\n",
    "    imageio.mimsave(f'./plots/{folder}.gif', images, duration=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
